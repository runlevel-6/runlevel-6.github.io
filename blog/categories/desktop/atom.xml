<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: desktop | Runlevel-6]]></title>
  <link href="http:/runlevel-6.github.io/blog/categories/desktop/atom.xml" rel="self"/>
  <link href="http:/runlevel-6.github.io/"/>
  <updated>2015-02-18T23:32:32-05:00</updated>
  <id>http:/runlevel-6.github.io/</id>
  <author>
    <name><![CDATA[Ken Zahorec]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using BackupPC for Backing Up KVM Virtual Machines]]></title>
    <link href="http:/runlevel-6.github.io/blog/2015/02/12/backuppc-hypervisor-backup/"/>
    <updated>2015-02-12T20:40:29-05:00</updated>
    <id>http:/runlevel-6.github.io/blog/2015/02/12/backuppc-hypervisor-backup</id>
    <content type="html"><![CDATA[<h2>Linux Mint 17.1 Fully Automated Backup of KVM Hypervisor Client Virtual Machines and other Host Systems.</h2>

<p>I recently spent some time researching open source backup solutions for KVM virtual machines (VMs) and discovered BackupPC.
BackupPC is a server-based enterprise grade backup solution which can be used to backup data from various hosts including Windows Desktop/Server, Linux/UNIX, and OS X, or any other system that can have files collected across a network using common secure protocols for access, sharing, and/or transferring file system data.</p>

<p>By adding a pre-backup VM dump process and a post-backup cleanup process, we can safely and reliably dump and then backup virtual machines from a hypervisor client host. After the backup data has been transfered to the backuppc host we can then clean up the VM dump data to ready the dump area for the next backup operation.
All of these operations are, of course, automated using BackupPC.
We are currently backing up about 6.5TB worth of VM backups consisting of multiple full and multiple incremental backups. This is requiring only about 800GB of pool storage at the BackupPC host&ndash;a very efficient solution.
We can restore a VM to any point in past history as defined in the configured backuppc schedule.
Backups age off of the system automatically.
In addition to automated full and incremental backups, a full or incremental backup can be manually initiated any time we wish.</p>

<p>Below is a server client host summary view of the BackupPC UI. It shows the hypervisor clients currently registered as clients for backup operations.</p>

<p><a href="http:/runlevel-6.github.io/images-backuppc/backuppc-server_sec.png" target="_blank" title="BackupPC server summary (click to open enlarged view)"> <img src="http:/runlevel-6.github.io/images-backuppc/backuppc-server_400x247_sec.png" border="0" alt="BackupPC UI in Firefox web browser" /></a></p>

<p>The BackupPC server provides scheduled backups, both full and/or incremental backups, and a multitude of enterprise features such as backup aging, blackout periods, de-duped storage, etc.
We can safely backup 5 TB to 10 TB of VM data within about 1TB of backup pool storage. It is very efficient.
The solution has been working very well for several weeks, so far, with no problems at all.</p>

<p>Below is a specific host client view summary for hypervisor client et-virt104.</p>

<p><a href="http:/runlevel-6.github.io/images-backuppc/backuppc-host-full_sec.png" target="_blank" title="BackupPC server summary full view (click to open enlarged view)"> <img src="http:/runlevel-6.github.io/images-backuppc/backuppc-host-full_400x339_sec.png" border="0" alt="BackupPC UI in Firefox web browser" /></a></p>

<h2>Dumping VMs to Ready them for Backup</h2>

<p>I spent some time with Daniel Berteaud&rsquo;s
<a href="http://gitweb.firewall-services.com/?p=virt-backup;a=blob_plain;f=virt-backup;hb=HEAD" target="_blank">virt-backup.pl script</a>,
but found that it was causing problems with libvirtd in CentOS 6 KVM hypervisors.
It would hang libvirtd, requiring a restart.
I spent a few days digging to find the root cause, but due to the time it was taking I decided to abandon the approach altogether.
On a side note, I was able to get virt-backup.pl to function properly on a CentOS 7 KVM hypervisor to successfully dump the VMs, but did not test it enough to be able to recommend it.</p>

<h2>Bash Script vm-clone-dump.sh for Hypervisor VM Dump and Cleanup</h2>

<p>I decided to write a bash script that would be based on available command line utilities for managing VMs through libvirt. Focusing on simiplicity, I wrote
<a href="http:/runlevel-6.github.io/vm-clone-dump/" target="_blank">vm-clone-dump.sh</a>
to use common libvirt tooling, virsh and virt-clone, for the required controlling and dumping of VMs. It is called vm-clone-dump.sh because it actually dumps a temporary clone of each VM along with XML definition of the clone and the XML definition of the original VM. The clone storage image is an exact duplicate of the orignal, which can be easily used to restore the original.
To restore a VM:</p>

<ol>
<li><p>Restore the virtual disk image and both XML files from the BackupPC server back to the virt-backup dump area of the hypervisow.
This is easily done in the UI for BackupPC. Just select the host, select the backup, then checkbox the desired files from the backup and hit the restore button.
The files will be restored to the configured dump directory on the hypervisor storage system.
Large files, such as VM images may take some time to restore.</p></li>
<li><p>After the image(s) and XML files have been restored to the hypervisor, you would then make sure the VM is shutdown.</p></li>
<li><p>Copy the cloned backup image data over to the same filespec as the original VM in /var/lib/libvirt/images.
You can tell exactly what the filespec is supposed to be by inspecting the original VM XML data.</p></li>
<li><p>In most cases there is no need to restore the XML data, unless perhaps it has changed since backup. A quick &ldquo;diff&rdquo; will tell you.
The VM XML files for the hypervisor normally reside in /etc/libvirtd/qemu/. If you do change the VM XML, you will need to restart libvirtd to reload the VM XML files before you can use the new XML definition. A full hypervisor system restart is not necessary. Restarting libvirtd will not interrupt any currently running VMs at the hypervisor.</p></li>
<li><p>Finally you can start the restored VM.</p></li>
</ol>


<p>Feel free to download the <a href="http:/runlevel-6.github.io/vm-clone-dump/vm-clone-dump.sh" target="_blank">vm-clone-dump.sh</a> script and use it in your KVM hypervisor. Invoke it with the -h option and it will produce help text on general dump processing and script usage.</p>

<p>The vm-clone-dump.sh script provides a &ldquo;standard dump&rdquo; and a &ldquo;concurrent dump&rdquo; processing option.
Standard dump will pause all VMs while the dump operation takes place.
Standard dump allows the hypervisor to spend the shortest amount of time dumping all of the VMs during the pre-backup processing, while all of the running VMs are paused.
The tradeoff here is requiring all VMs to be paused, resulting in slightly more overall VM downtime.
Concurrent dump will indvidually pause each VM, dump it, then resume it before going on to the next VM. Concurrent dump is meant to improve uptime for VMs during the hypervisor pre-backup dump operation at the expense of taking a bit more time to dump all of the VMs.</p>

<p>The dump operation will dump all running and/or shutdown VMs. It will not dump paused or transitional VMs. It will dump writable filesystems, but not dump read-only filesystems&ndash;such as mounted CDROM .iso images.</p>

<p>The hypervisor VM dump method chosen, standard or concurrent, is provided as a command option.
The best use of it depends on the capabilities and loading of the hypervisor server storage system.
I am finding that the standard dump method works best on older servers, such as the Dell 2950 (10K RPM SATA RAID storage), while the concurrent dump seems to work best on newer servers, such as the Cicso C220 M3 (solid state RAID storage).
The Cisco C220 M3 server dumps VMs in a few short minutes (~10 minutes) while the older, aging, Dell 2950 takes far longer (~5 hours) to complete a similar VM dump&ndash;a dramatic difference indeed.</p>

<h2>Linux Mint 17.1 Server Setup for Backup of KVM Hypervisor Client Virtual Machines and other Host Systems.</h2>

<p>I decided to install backuppc into a
<a href="http://www.linuxmint.com/" target="_blank">Linux Mint</a>
desktop system which, in this particular case, functions as a great backup server.
I chose the Linux Mint desktop distribution because it provides a super friendly graphical desktop, Cinnamon. The backuppc solution could be setup, as well, on Ubuntu or Debian and other Linux distributions as well.
A stable version of backuppc was available for installation directly from the Linux Mint repositories and took literally seconds to install.
Here are the general
<a href="http:/runlevel-6.github.io/linux-mint-backuppc/" target="_blank">instructions for installing and setting up BackupPC on Linux Mint.</a>
Hopefully you will find them useful in building your own BackupPC envionment.</p>

<p>Once the BackupPC packages are installed and configured you can log into the backuppc website, either locally or remotely, to manage the BackupPC server. Add hosts, adjust the backup schedule, and let the backup automation begin! Run your hypervisor VMs with confidence in knowing that the VMs are being regularly backed up and can be easily restored as desired.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux Mint 17.1 with KVM/Qemu hypervisor and VM management]]></title>
    <link href="http:/runlevel-6.github.io/blog/2015/01/13/linux-mint-with-hypervisor/"/>
    <updated>2015-01-13T23:40:29-05:00</updated>
    <id>http:/runlevel-6.github.io/blog/2015/01/13/linux-mint-with-hypervisor</id>
    <content type="html"><![CDATA[<p>Linux Mint is one of my favorite Linux desktop distributions. It comes in a multitude of flavors designed to drop into just about any desktop or laptop system available. It installs and updates in minutes and delivers a fully functional system with a full set of common and very useful applications&ndash;everything that most any user would need. The latest version 17.1 is a long term support (LTS) release which means it is supported for 5 years. Linux Mint is my go-to distribution for desktop Linux. The folks on the Linux Mint team have been doing a phenominal job, release after release, since the project started several years back.</p>

<p>Here we provide instructions for adding the KVM hypervisor and VM management tools to the Linux Mint 64-bit install. The Linux Mint system becomes a virtualization host. In a few minutes, with just a few commands, you can have a rock solid virtualization hypervisor added to your Linux Mint desktop system. You can use graphical &ldquo;virt-manager&rdquo; to create virtual machines and manage virtual networks. You can use the Spice protocol to offer high performance virtual desktop interfaces (VDI) both locally and to remote clients. Having the advantages of virtualization added to your Mint desktop provides some serious benefits for developing, testing, experimentation, or providing remote virtual desktop interface (VDI) services to others from your Linux Mint system. Virtualization also allows you to keep your main Mint desktop system clean and shiny while you use disposable VMs for software testing, experimentation, duplication, and validation.</p>

<p>You will need a system with some horsepower if you plan to run mulitple virtual machines and/or provide access to them from remote clients. The system processor must be capable of hardware based virtualization. A high end AMD (Athlon 64, A8, A10, or higher) or Intel system (I5, I7, Xeon, etc.) should provide this capability. Here is a good
<a href="http://superuser.com/questions/591813/how-to-tell-if-a-cpu-supports-virtualization" target="_blank">article from superuser.com</a>
on identifying processor virtualization. Any memory or processor resources provided to a VM while it is running will reduce the capacity of the virtualization host system. If you plan to have one or more resource intensive VMs, then you will need to provide enough processor, memory, and storage resource in your main host.</p>

<h3>Basic installation and update of Linux Mint</h3>

<p>Install Linux Mint 17.1 64-bit Cinnamon desktop from CD or USB. I won&rsquo;t get into the basic install details because there is plenty of information available on this and it is quite simple to install on just about any system. Select the installation icon on the desktop and follow through&ndash;this takes only a few minutes. In a flash you are ready to proceed with your shiny new Linux Mint system.</p>

<p>Open a terminal on the desktop. Perform an initial update to bring all of the components up to the latest available revisions.</p>

<pre><code>$ sudo apt-get update
$ sudo apt-get upgrade
</code></pre>

<h3>Secure shell remote client access to the Linux Mint system</h3>

<p>If you want to provide for remote management of the Mint system then add openssh secure shell server. This will provide for secure remote client access and secure remote file transfer to or from the Linux Mint host.</p>

<pre><code>$ sudo apt-get install openssh-server
</code></pre>

<h3>Adding the hypervisor and related components</h3>

<p>Now we begin adding the KVM hypervisor, Qemu emulator, libvirt management components, and graphical &ldquo;virt-manager&rdquo;</p>

<pre><code>$ sudo apt-get install qemu-system
$ sudo apt-get install qemu-utils
$ sudo apt-get install libvirt-bin
$ sudo apt-get install virt-manager
</code></pre>

<p>We want the ability to provide accelerated video to any connecting clients, so we add the SPICE client kit and virt-viewer. Virt-viewer is a view client which connects to either VNC or SPICE desktop video connections. It is similar to a RDP or VNC client.</p>

<pre><code>$ sudo apt-get install python-spice-client-gtk
$ sudo apt-get install virt-viewer
</code></pre>

<h3>Providing access to the hypervisor - the libvirtd group</h3>

<p>With all of the components installed, all that is left to do is add any user who will be connecting to the hypervisor into the libvirtd group. Upon the next login, the user will be able to run virt-manager, connect to the local hypervisor, and create and manage VMs.</p>

<h3>Managing VMs using the virsh command line</h3>

<p>VMs can be managed using graphical virt-manager, or through the command line using virsh. Here is an simple example session of listing available VMs and showing their current state.</p>

<pre><code>zuser@zbox00 ~ $ virsh list --all
 Id    Name                           State
----------------------------------------------------
 -     crunchbag-linux_00             shut off
 -     win-server-2012-r2             shut off
 -     win-server-2012-r2-template    shut off
 -     win7pro-spice-01               shut off
</code></pre>

<p>As you can see, they are all shut off. We start two of them using virsh at the command line&hellip;</p>

<pre><code>zuser@zbox00 ~ $ virsh start crunchbag-linux_00
Domain crunchbag-linux_00 started

zuser@zbox00 ~ $ virsh start win7pro-spice-01
Domain win7pro-spice-01 started

zuser@zbox00 ~ $ 
</code></pre>

<h3>Managing VMs using the graphical virt-manager</h3>

<p>VMs can be graphically managed using virt-manager. Here is a screenshot of virt-manager in action. The virt-manager application provides a very easy to use graphical interface which allows you to manage VMs and other virtual resources. You can also create virtual networks and adjust network backings, monitor resources, etc.</p>

<p><img src="/images-mint-hypervisor/virt-manager_400x417.png" title="Optional title" alt="graphic of virt-manger on Linux Mint desktop" /></p>

<p><a href="http:/runlevel-6.github.io/images-mint-hypervisor/virt-manager-connections.png" target="_blank"> <img src="http:/runlevel-6.github.io/images-mint-hypervisor/virt-manager-connections_400x250.png" border="0" alt="graphic of win 7 pro running VDI in local hypervisor" /></a></p>

<p>Using Linux remote-viewer, or Windows virt-viewer allows you to connect to the console via VNC or Spice display port on the VM.
This provide a virtual desktop interface (VDI). Spice provides accelerated performance to the desktop over the network.</p>

<h3>VDI - Accessing the VM guest&rsquo;s desktop through a remote, or local, client.</h3>

<p>The VDI experience is very fluid and provides excellent throughput for doing CAD and other graphics intensive work.
In this case the VM is located on the localhost Linux Mint KVM hypervisor, but this VM guest desktop can be provided anywhere we need it via Spice connection on the local network.
In most cases network bandwidth of only a few megabit is all that is needed.</p>

<p>The user of the desktop VDI needs only the viewing client, they do not need access to virt-manager.
Access to the console, through the client, can be protected using a digest password and will require separate login with account credentials to the VM guest.
It looks just like a physically connected console&ndash;if you restart the OS guest in the VDI you can watch it reboot with BIOS screen and boot to running system.
With installation of libvirt guest OS tools we get auto-resizing, and copy-paste capabilities between the remote-viewer client and accessing system.
Spice provides also for forwarding of USB connections to the guest as well as use of local sound devices. You can run multiple console displays as well.</p>

<p>The example below is of a Windows 7 Pro 64-bit VM guest running Solid Works through a Spice VDI. The VM is running on a Linux Mint notebook with the KVM hypervisor added to it. The example is shown in windowed mode, but can run very well in auto-adjusted full screen native resolution as well.</p>

<p><a href="http:/runlevel-6.github.io/images-mint-hypervisor/win7-spice-vdi-solid-works.png" target="_blank"> <img src="http:/runlevel-6.github.io/images-mint-hypervisor/win7-spice-vdi-solid-works_400x225.png" border="0" alt="win 7 pro running VDI in local hypervisor" /></a></p>

<p><a href='#TOP'><img alt="back to top of page" style="border-width:0" src="http:/runlevel-6.github.io/images/nav-to-top_80x23.png" /></a></p>
]]></content>
  </entry>
  
</feed>
